Index: contrib/altq/altq/altq_classq.h
===================================================================
RCS file: /home/ncvs/src/sys/contrib/altq/altq/altq_classq.h,v
retrieving revision 1.1.1.1
diff -u -r1.1.1.1 altq_classq.h
--- contrib/altq/altq/altq_classq.h	12 Jun 2004 00:10:14 -0000	1.1.1.1
+++ contrib/altq/altq/altq_classq.h	23 Jan 2010 23:45:01 -0000
@@ -78,6 +78,7 @@
 #if !defined(__GNUC__) || defined(ALTQ_DEBUG)
 
 extern void		_addq(class_queue_t *, struct mbuf *);
+extern void             _insq(class_queue_t *, struct mbuf *, struct mbuf *);
 extern struct mbuf	*_getq(class_queue_t *);
 extern struct mbuf	*_getq_tail(class_queue_t *);
 extern struct mbuf	*_getq_random(class_queue_t *);
@@ -102,6 +103,24 @@
 	qlen(q)++;
 }
 
+/* insert packet after pointed one, or on head if NULL*/
+static __inline void
+_insq(class_queue_t *q, struct mbuf *m, struct mbuf *memb)
+{
+                if (memb != NULL) {
+                        m->m_nextpkt = memb->m_nextpkt;
+                        memb->m_nextpkt = m;
+                        if (qtail(q) == memb) qtail(q) = m;    // relink new tail
+                } else {
+                        if (qtail(q) != NULL)
+                                m->m_nextpkt = qtail(q)->m_nextpkt;
+                        else
+                                qtail(q) = m;
+                        qtail(q)->m_nextpkt = m;
+                }
+                qlen(q)++;
+}
+
 static __inline struct mbuf *
 _getq(class_queue_t *q)
 {
Index: contrib/altq/altq/altq_red.c
===================================================================
RCS file: /home/ncvs/src/sys/contrib/altq/altq/altq_red.c,v
retrieving revision 1.5
diff -u -r1.5 altq_red.c
--- contrib/altq/altq/altq_red.c	23 Oct 2008 15:53:51 -0000	1.5
+++ contrib/altq/altq/altq_red.c	23 Jan 2010 23:45:05 -0000
@@ -1,4 +1,4 @@
-/*	$FreeBSD: src/sys/contrib/altq/altq/altq_red.c,v 1.5 2008/10/23 15:53:51 des Exp $	*/
+/*	$FreeBSD: src/sys/contrib/altq/altq/altq_red.c,v 1.4.6.1 2008/11/25 02:59:29 kensmith Exp $	*/
 /*	$KAME: altq_red.c,v 1.18 2003/09/05 22:40:36 itojun Exp $	*/
 
 /*
@@ -233,7 +233,7 @@
 	int	 w, i;
 	int	 npkts_per_sec;
 
-	rp = malloc(sizeof(red_t), M_DEVBUF, M_WAITOK);
+	MALLOC(rp, red_t *, sizeof(red_t), M_DEVBUF, M_WAITOK);
 	if (rp == NULL)
 		return (NULL);
 	bzero(rp, sizeof(red_t));
@@ -321,7 +321,7 @@
 #endif
 #endif /* ALTQ3_COMPAT */
 	wtab_destroy(rp->red_wtab);
-	free(rp, M_DEVBUF);
+	FREE(rp, M_DEVBUF);
 }
 
 void
@@ -335,142 +335,224 @@
 	sp->marked_packets	= rp->red_stats.marked_packets;
 }
 
+#define MHASH_STUB     0x0100007fu
+
+/*
+ *  Count packet's destination (or source) address hash
+ *  TODOs:
+ *    > cache hash on mbuf
+ *    > hash ipv6 addresses
+ */
+
+u_int
+hps_pkt_hash(struct mbuf *m, struct altq_pktattr *pktattr, int flags)
+{
+        struct mbuf     *m0;
+        struct ip       *hdr;
+        struct pf_mtag  *at;
+        int              af;
+
+        m0  = 0;
+
+
+        at = pf_find_mtag(m);
+        if (at != NULL) {
+                af = at->af;
+                hdr = at->hdr;
+#ifdef ALTQ3_COMPAT
+        } else if (pktattr != NULL) {
+                af = pktattr->pattr_af;
+                hdr = pktattr->pattr_hdr;
+#endif /* ALTQ3_COMPAT */
+        } else
+                return (MHASH_STUB);
+
+        switch (af) {
+        case AF_INET:
+
+        /* STUB: just return v4 address as hash */
+                if (flags & REDF_ECN)
+                        return hdr->ip_src.s_addr;
+                else
+                        return hdr->ip_dst.s_addr;
+        /* TODO: v6 hash */
+
+        }
+
+/* else - return STUB hash */
+        return MHASH_STUB;
+}
+
+/*
+ *  Get packet's (pre-cached to be) hash (stub)
+ */
+
+#define pkt_hash(m)  (hps_pkt_hash(m, pktattr, rp->red_flags))
+
+/*
+ *  Enqueue new packet
+ */
+
 int
 red_addq(red_t *rp, class_queue_t *q, struct mbuf *m,
     struct altq_pktattr *pktattr)
 {
-	int avg, droptype;
-	int n;
-#ifdef ALTQ3_COMPAT
-#ifdef ALTQ_FLOWVALVE
-	struct fve *fve = NULL;
+        struct    mbuf *m0;  /* tail or head storage */
 
-	if (rp->red_flowvalve != NULL && rp->red_flowvalve->fv_flows > 0)
-		if (fv_checkflow(rp->red_flowvalve, pktattr, &fve)) {
-			m_freem(m);
-			return (-1);
-		}
-#endif
-#endif /* ALTQ3_COMPAT */
+        struct    mbuf *mi;  /* queue walk index   */
+        struct    mbuf *mp;  /* previous index     */
+        struct    mbuf *mc;  /* candidate item     */
 
-	avg = rp->red_avg;
+        u_int     mhash;     /* new packet hash    */
+        u_int     ihash = 0;  /* indexed item hash  */
+        u_int     phash = 0; /* previous item hash */
 
-	/*
-	 * if we were idle, we pretend that n packets arrived during
-	 * the idle period.
-	 */
-	if (rp->red_idle) {
-		struct timeval now;
-		int t;
-
-		rp->red_idle = 0;
-		microtime(&now);
-		t = (now.tv_sec - rp->red_last.tv_sec);
-		if (t > 60) {
-			/*
-			 * being idle for more than 1 minute, set avg to zero.
-			 * this prevents t from overflow.
-			 */
-			avg = 0;
-		} else {
-			t = t * 1000000 + (now.tv_usec - rp->red_last.tv_usec);
-			n = t / rp->red_pkttime - 1;
+        int       qpkts;     /* number of packets (w/ same hash) */
+        int       fhead;
 
-			/* the following line does (avg = (1 - Wq)^n * avg) */
-			if (n > 0)
-				avg = (avg >> FP_SHIFT) *
-				    pow_w(rp->red_wtab, n);
-		}
-	}
+        int       n;
 
-	/* run estimator. (note: avg is scaled by WEIGHT in fixed-point) */
-	avg += (qlen(q) << FP_SHIFT) - (avg >> rp->red_wshift);
-	rp->red_avg = avg;		/* save the new value */
+        int       qhosts;    /* number of hosts (stub) */
 
-	/*
-	 * red_count keeps a tally of arriving traffic that has not
-	 * been dropped.
-	 */
-	rp->red_count++;
+/* count & cache packet hash (hope, qiq is unneeded anymore) */
+	mhash = hps_pkt_hash(m, pktattr, rp->red_flags); 
 
-	/* see if we drop early */
-	droptype = DTYPE_NODROP;
-	if (avg >= rp->red_thmin_s && qlen(q) > 1) {
-		if (avg >= rp->red_thmax_s) {
-			/* avg >= th_max: forced drop */
-			droptype = DTYPE_FORCED;
-		} else if (rp->red_old == 0) {
-			/* first exceeds th_min */
-			rp->red_count = 1;
-			rp->red_old = 1;
-		} else if (drop_early((avg - rp->red_thmin_s) >> rp->red_wshift,
-				      rp->red_probd, rp->red_count)) {
-			/* mark or drop by red */
-			if ((rp->red_flags & REDF_ECN) &&
-			    mark_ecn(m, pktattr, rp->red_flags)) {
-				/* successfully marked.  do not drop. */
-				rp->red_count = 0;
-#ifdef RED_STATS
-				rp->red_stats.marked_packets++;
+#ifdef HPS_DEBUG
+        printf("hash=%x\n", mhash);
 #endif
-			} else {
-				/* unforced drop by red */
-				droptype = DTYPE_EARLY;
-			}
-		}
-	} else {
-		/* avg < th_min */
-		rp->red_old = 0;
-	}
 
-	/*
-	 * if the queue length hits the hard limit, it's a forced drop.
-	 */
-	if (droptype == DTYPE_NODROP && qlen(q) >= qlimit(q))
-		droptype = DTYPE_FORCED;
+/* shortcut - abort on (global) queue overflow */
+        if (qlen(q) >= qlimit(q)) {
+                m_freem(m);
+                return (-1);
+        }
+
+/* shortcut - just add if queue is empty */
+        if ((m0 = qtail(q)) == NULL) {
+                _addq(q, m);
+                return 0;
+        }
+
+/*
+ *
+ * walk thru queue, in order to:
+ * > find a place for new packet
+ * > count same-hashed packets to detect personal overflow
+ * > ? count number of active hosts
+ *
+ */
+
+/* prepare to walk */
+
+        mi = m0;              /* current item ptr (set to tail)   */
+        mp = NULL;            /* previous item (NULL = n/a)       */
+	mc = m;               /* place candidate (self - none, NULL - head) */
+        m0  = m0->m_nextpkt;  /* store head ptr (as loop marker)  */
+        qpkts  = 0;           /* number of packets with same hash */
+        qhosts = 0;           /* number of active hosts detected  */
+        fhead  = 0;           /* can put packet on head           */
+
+/* do walk thru queue */
+        do {
+        /* store previous */
+                if (mi->m_nextpkt != m0) {
+                        mp    = mi;
+                        phash = ihash;
+                }
+        /* set on next (or first) item */
+                mi    = mi->m_nextpkt;
+                ihash = pkt_hash(mi);
+
+        /* hash is equal - skip, count */
+                if (ihash == mhash) {
+                        qpkts++;  // count packets
+                        continue;
+                }
+
+                if (mp == NULL) {
+                        if (ihash > mhash) fhead = 1;
+                } else {
+                        if (phash == ihash ||
+                                (phash > ihash && phash < mhash) ||
+                                (ihash > mhash && phash < mhash))
+                                mc = mp;
+                }
+        } while(mi->m_nextpkt != m0 && mc == m);
+
+        qhosts = 20;  /* STUB */
+
+/* count host queue limit */
+
+#if 0
+/* dynamic host queue limit */
+        n = qlimit(q)/qhosts;
+
+/* check limit range */
+        if (n < 25)
+                n = 25;
+        else if (n > (qlimit(q)/2))
+                n = qlimit(q)/2;
 
-#ifdef RED_RANDOM_DROP
-	/* if successful or forced drop, enqueue this packet. */
-	if (droptype != DTYPE_EARLY)
-		_addq(q, m);
 #else
-	/* if successful, enqueue this packet. */
-	if (droptype == DTYPE_NODROP)
-		_addq(q, m);
-#endif
-	if (droptype != DTYPE_NODROP) {
-		if (droptype == DTYPE_EARLY) {
-			/* drop the incoming packet */
-#ifdef RED_STATS
-			rp->red_stats.drop_unforced++;
-#endif
-		} else {
-			/* forced drop, select a victim packet in the queue. */
-#ifdef RED_RANDOM_DROP
-			m = _getq_random(q);
-#endif
-#ifdef RED_STATS
-			rp->red_stats.drop_forced++;
-#endif
-		}
-#ifdef RED_STATS
-		PKTCNTR_ADD(&rp->red_stats.drop_cnt, m_pktlen(m));
-#endif
-		rp->red_count = 0;
-#ifdef ALTQ3_COMPAT
-#ifdef ALTQ_FLOWVALVE
-		if (rp->red_flowvalve != NULL)
-			fv_dropbyred(rp->red_flowvalve, pktattr, fve);
+/* fixed host queue limit */
+	if (qlimit(q) >= 2000)
+	        n = qlimit(q)/4;
+	else
+		n = qlimit(q);
 #endif
-#endif /* ALTQ3_COMPAT */
-		m_freem(m);
-		return (-1);
-	}
-	/* successfully queued */
-#ifdef RED_STATS
-	PKTCNTR_ADD(&rp->red_stats.xmit_cnt, m_pktlen(m));
+
+/* check host's limit & drop */
+/* (do not allow queue to be overflowed by sigle host) */
+        if (qpkts >= n) {
+                m_freem(m);
+                return (-1);
+        }
+
+/* add/insert packet to queue */
+        if (mc == m)
+                _addq(q, m);                   /* put to tail */
+        else {
+                if (fhead != 0 && qpkts == 0)
+                        _insq(q, m, NULL);     /* put to head */
+                else
+                        _insq(q, m, mc);       /* insert to queue */
+        }
+
+#ifdef HPS_DEBUG
+        mi = qtail(q);
+        m0 = qtail(q)->m_nextpkt;
+
+        printf("queue: ");
+        do {
+                mi = mi->m_nextpkt;
+                printf("%x, ", pkt_hash(mi));
+        } while(mi->m_nextpkt != m0);
+        printf("\n");
 #endif
-	return (0);
+
+        return (0);
 }
 
 /*
@@ -646,7 +728,7 @@
 			return (w);
 		}
 
-	w = malloc(sizeof(struct wtab), M_DEVBUF, M_WAITOK);
+	MALLOC(w, struct wtab *, sizeof(struct wtab), M_DEVBUF, M_WAITOK);
 	if (w == NULL)
 		panic("wtab_alloc: malloc failed!");
 	bzero(w, sizeof(struct wtab));
@@ -682,7 +764,7 @@
 			break;
 		}
 
-	free(w, M_DEVBUF);
+	FREE(w, M_DEVBUF);
 	return (0);
 }
 
@@ -816,17 +898,17 @@
 		}
 
 		/* allocate and initialize red_queue_t */
-		rqp = malloc(sizeof(red_queue_t), M_DEVBUF, M_WAITOK);
+		MALLOC(rqp, red_queue_t *, sizeof(red_queue_t), M_DEVBUF, M_WAITOK);
 		if (rqp == NULL) {
 			error = ENOMEM;
 			break;
 		}
 		bzero(rqp, sizeof(red_queue_t));
 
-		rqp->rq_q = malloc(sizeof(class_queue_t),
+		MALLOC(rqp->rq_q, class_queue_t *, sizeof(class_queue_t),
 		       M_DEVBUF, M_WAITOK);
 		if (rqp->rq_q == NULL) {
-			free(rqp, M_DEVBUF);
+			FREE(rqp, M_DEVBUF);
 			error = ENOMEM;
 			break;
 		}
@@ -834,8 +916,8 @@
 
 		rqp->rq_red = red_alloc(0, 0, 0, 0, 0, 0);
 		if (rqp->rq_red == NULL) {
-			free(rqp->rq_q, M_DEVBUF);
-			free(rqp, M_DEVBUF);
+			FREE(rqp->rq_q, M_DEVBUF);
+			FREE(rqp, M_DEVBUF);
 			error = ENOMEM;
 			break;
 		}
@@ -854,8 +936,8 @@
 				    NULL, NULL);
 		if (error) {
 			red_destroy(rqp->rq_red);
-			free(rqp->rq_q, M_DEVBUF);
-			free(rqp, M_DEVBUF);
+			FREE(rqp->rq_q, M_DEVBUF);
+			FREE(rqp, M_DEVBUF);
 			break;
 		}
 
@@ -1016,8 +1098,8 @@
 	}
 
 	red_destroy(rqp->rq_red);
-	free(rqp->rq_q, M_DEVBUF);
-	free(rqp, M_DEVBUF);
+	FREE(rqp->rq_q, M_DEVBUF);
+	FREE(rqp, M_DEVBUF);
 	return (error);
 }
 
@@ -1297,16 +1379,16 @@
 	int i, num;
 
 	num = FV_FLOWLISTSIZE;
-	fv = malloc(sizeof(struct flowvalve),
+	MALLOC(fv, struct flowvalve *, sizeof(struct flowvalve),
 	       M_DEVBUF, M_WAITOK);
 	if (fv == NULL)
 		return (NULL);
 	bzero(fv, sizeof(struct flowvalve));
 
-	fv->fv_fves = malloc(sizeof(struct fve) * num,
+	MALLOC(fv->fv_fves, struct fve *, sizeof(struct fve) * num,
 	       M_DEVBUF, M_WAITOK);
 	if (fv->fv_fves == NULL) {
-		free(fv, M_DEVBUF);
+		FREE(fv, M_DEVBUF);
 		return (NULL);
 	}
 	bzero(fv->fv_fves, sizeof(struct fve) * num);
@@ -1323,11 +1405,11 @@
 	fv->fv_pthresh = (FV_PSCALE(1) << FP_SHIFT) / rp->red_inv_pmax;
 
 	/* initialize drop rate to fraction table */
-	fv->fv_p2ftab = malloc(sizeof(int) * BRTT_SIZE,
+	MALLOC(fv->fv_p2ftab, int *, sizeof(int) * BRTT_SIZE,
 	       M_DEVBUF, M_WAITOK);
 	if (fv->fv_p2ftab == NULL) {
-		free(fv->fv_fves, M_DEVBUF);
-		free(fv, M_DEVBUF);
+		FREE(fv->fv_fves, M_DEVBUF);
+		FREE(fv, M_DEVBUF);
 		return (NULL);
 	}
 	/*
@@ -1348,9 +1430,9 @@
 static void fv_destroy(fv)
 	struct flowvalve *fv;
 {
-	free(fv->fv_p2ftab, M_DEVBUF);
-	free(fv->fv_fves, M_DEVBUF);
-	free(fv, M_DEVBUF);
+	FREE(fv->fv_p2ftab, M_DEVBUF);
+	FREE(fv->fv_fves, M_DEVBUF);
+	FREE(fv, M_DEVBUF);
 }
 
 static __inline int
Index: contrib/altq/altq/altq_red.h
===================================================================
RCS file: /home/ncvs/src/sys/contrib/altq/altq/altq_red.h,v
retrieving revision 1.1.1.1
diff -u -r1.1.1.1 altq_red.h
--- contrib/altq/altq/altq_red.h	12 Jun 2004 00:10:04 -0000	1.1.1.1
+++ contrib/altq/altq/altq_red.h	23 Jan 2010 23:45:05 -0000
@@ -193,6 +193,12 @@
 extern int		 wtab_destroy(struct wtab *);
 extern int32_t		 pow_w(struct wtab *, int);
 
+u_int                    hps_pkt_hash(struct mbuf *, struct altq_pktattr *, int);
+
+#if 0
+#define HPS_DEBUG
+#endif
+
 #endif /* _KERNEL */
 
 #endif /* _ALTQ_ALTQ_RED_H_ */
Index: contrib/altq/altq/altq_rmclass.c
===================================================================
RCS file: /home/ncvs/src/sys/contrib/altq/altq/altq_rmclass.c,v
retrieving revision 1.3
diff -u -r1.3 altq_rmclass.c
--- contrib/altq/altq/altq_rmclass.c	23 Oct 2008 15:53:51 -0000	1.3
+++ contrib/altq/altq/altq_rmclass.c	23 Jan 2010 23:45:08 -0000
@@ -1,4 +1,4 @@
-/*	$FreeBSD: src/sys/contrib/altq/altq/altq_rmclass.c,v 1.3 2008/10/23 15:53:51 des Exp $	*/
+/*	$FreeBSD: src/sys/contrib/altq/altq/altq_rmclass.c,v 1.2.26.1 2008/11/25 02:59:29 kensmith Exp $	*/
 /*	$KAME: altq_rmclass.c,v 1.18 2003/11/06 06:32:53 kjc Exp $	*/
 
 /*
@@ -220,16 +220,16 @@
 	}
 #endif
 
-	cl = malloc(sizeof(struct rm_class),
+	MALLOC(cl, struct rm_class *, sizeof(struct rm_class),
 	       M_DEVBUF, M_WAITOK);
 	if (cl == NULL)
 		return (NULL);
 	bzero(cl, sizeof(struct rm_class));
 	CALLOUT_INIT(&cl->callout_);
-	cl->q_ = malloc(sizeof(class_queue_t),
+	MALLOC(cl->q_, class_queue_t *, sizeof(class_queue_t),
 	       M_DEVBUF, M_WAITOK);
 	if (cl->q_ == NULL) {
-		free(cl, M_DEVBUF);
+		FREE(cl, M_DEVBUF);
 		return (NULL);
 	}
 	bzero(cl->q_, sizeof(class_queue_t));
@@ -658,8 +658,8 @@
 			red_destroy(cl->red_);
 #endif
 	}
-	free(cl->q_, M_DEVBUF);
-	free(cl, M_DEVBUF);
+	FREE(cl->q_, M_DEVBUF);
+	FREE(cl, M_DEVBUF);
 }
 
 
@@ -1739,6 +1739,24 @@
 	qlen(q)++;
 }
 
+/* insert packet after pointed one, or on head if NULL*/
+void
+_insq(class_queue_t *q, struct mbuf *m, struct mbuf *memb)
+{
+                if (memb != NULL) {
+                        m->m_nextpkt = memb->m_nextpkt;
+                        memb->m_nextpkt = m;
+                        if (qtail(q) == memb) qtail(q) = m;    // relink new tail
+                } else {
+                        if (qtail(q) != NULL)
+                                m->m_nextpkt = qtail(q)->m_nextpkt;
+                        else
+                                qtail(q) = m;
+                        qtail(q)->m_nextpkt = m;
+                }
+                qlen(q)++;
+}
+
 mbuf_t *
 _getq(class_queue_t *q)
 {
